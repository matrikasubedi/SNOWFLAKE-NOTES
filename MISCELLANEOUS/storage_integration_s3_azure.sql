CREATE OR REPLACE TABLE CONSUM_COMPLAINTS
  (   DATE_RECEIVED STRING ,
      PRODUCT_NAME VARCHAR2(50) , 
      SUB_PRODUCT  VARCHAR2(100) , 
      ISSUE  VARCHAR2(100), 
      SUB_ISSUE  VARCHAR2(100),
      CONSUMER_COMPLAINT_NARRATIVE STRING,
      Company_Public_Response  STRING,
      Company VARCHAR(80),
      State_Name CHAR(4),
      Zip_Code STRING,
      Tags  VARCHAR(60),
      Consumer_Consent_Provided CHAR(20),
       Submitted_via STRING,
      Date_Sent_to_Company  STRING,
     Company_Response_to_Consumer VARCHAR(80),
     Timely_Response CHAR(4),
     CONSUMER_DISPUTED CHAR(4),
     COMPLAINT_ID  NUMBER(12,0) NOT NULL PRIMARY KEY
  ) ;

SELECT * FROM CONSUM_COMPLAINTS;

CREATE OR REPLACE TABLE CONSUM_COMPLAINTS_COPY AS
SELECT * FROM CONSUM_COMPLAINTS;

CREATE OR REPLACE TABLE CONSUM_COMPLAINTS_AWS LIKE CONSUM_COMPLAINTS;
SHOW COLUMNS IN CONSUM_COMPLAINTS_AWS;

##### LAODING A FILE FROM EXTERNAL STAGE - AWS ##########

CREATE OR REPLACE TABLE CONSUM_COMPLAINTS_AWS LIKE CONSUM_COMPLAINTS;
SHOW COLUMNS IN CONSUM_COMPLAINTS_AWS;

--list stage confirm if its empty
LIST @AWS_S3_STORAGE_SERVICE;

----list stage confirm if its empty
LIST @AZURE_STORAGE;

##### LOADING A FILE FROM EXTERNAL STAGE - AZURE ##########
CREATE OR REPLACE TABLE CONSUM_COMPLAINTS_AZURE LIKE CONSUM_COMPLAINTS;
SHOW COLUMNS IN CONSUM_COMPLAINTS_AZURE;

--COPYING INTO AZURE STORAGE SERVICE
COPY INTO CONSUM_COMPLAINTS_AZURE FROM @AZURE_STORAGE
FILE_FORMAT = (TYPE = CSV FIELD_DELIMITER = ',' SKIP_HEADER = 1)
PURGE = TRUE;

--BINGO
SELECT * FROM CONSUM_COMPLAINTS_AZURE;

--REMOVE FILES
REMOVE @AWS_S3_STORAGE_SERVICE;


--
##COPYING INTO STORAGE SERVICE
COPY INTO CONSUM_COMPLAINTS_AWS FROM @AWS_S3_STORAGE_SERVICE
FILE_FORMAT = (TYPE = CSV FIELD_DELIMITER = ',' SKIP_HEADER = 1)
PURGE = TRUE;

--BINGO DONE....
SELECT * FROM CONSUM_COMPLAINTS_AWS;


------------------------------------------------------------------------------------------------------------------
CREATE OR REPLACE TABLE PATIENTS(
PATIENTID INT,
FIRST_NAME VARCHAR(100),
CITY VARCHAR(100),
REGISTATIONYEAR INT
);


DROP TABLE HEALTHCARE;

CREATE OR REPLACE TABLE AJ_HEALTHCARE(  
Patientid VARCHAR(15),	
gender CHAR(8),	
age VARCHAR(5)	,
hypertension CHAR(20),	
heart_disease CHAR(20),	
ever_married CHAR(30),	
work_type VARCHAR(60),	
Residence_type CHAR(30)	,
avg_glucose_level VARCHAR(20),	
bmi VARCHAR(20)	,
smoking_status	VARCHAR(20),
stroke CHAR(20)
);

CREATE OR REPLACE STORAGE integration aj_stage_int
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3
ENABLED = TRUE
STORAGE_AWS_ROLE_ARN ='arn:aws:iam::441615131317:role/mynewawsrole'
STORAGE_ALLOWED_LOCATIONS = ('s3://ajawssnowflakebucket/');

desc integration aj_stage_int;


CREATE OR REPLACE STAGE AJ_STG_HEALTHCARE
URL ='s3://ajawssnowflakebucket'
--credentialsa not required
--credentials=(aws_key_id='AKIAWNUSQEK2U7NPSOMJ'aws_secret_key='sT5bIgNGpIPuN19IEzYDebYX9RSnhLmERNS9j0RV')
file_format=CSV
storage_integration = aj_stage_int;

LIST @AJ_STG_HEALTHCARE;

SHOW STAGES;

--CREATE SNOWPIPE THAT RECOGNISES CSV THAT ARE INGESTED FROM EXTERNAL STAGE AND COPIES THE DATA INTO PATIENTS TABLE
--The AUTO_INGEST=true parameter specifies to read event notifications sent from an S3 bucket to an SQS queue when new data is ready to load.


CREATE OR REPLACE PIPE AJ_HEALTHCARE_SNOWPIPE AUTO_INGEST = TRUE AS
COPY INTO "DATA_PIPELINING"."PUBLIC"."AJ_HEALTHCARE"
FROM @AJ_STG_HEALTHCARE
FILE_FORMAT = CSV;
 
SHOW PIPES;

---copy into "DATA_PIPELINING"."PUBLIC"."AJ_HEALTHCARE"
---from @AJ_STG_HEALTHCARE
---FILE_FORMAT = (FORMAT_NAME = CSV) ON_ERROR = CONTINUE;

SELECT count(*) FROM AJ_HEALTHCARE;

select * from AJ_HEALTHCARE;
alter pipe HEALTHCARE_SNOWPIPE refresh;

SELECT SYSTEM$PIPE_STATUS('HEALTHCARE_SNOWPIPE');}









